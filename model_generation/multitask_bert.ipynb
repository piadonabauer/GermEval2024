{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Task Transformer\n",
    "\n",
    "In this notebook, a multi-task transformer based on the pre-trained [BERT](https://huggingface.co/google-bert/bert-base-german-cased) model is constructed, where each task corresponds to one annotator. For each data point, the CLS token is extracted and scored using a tf-idf dictionary created from the dataframe.\n",
    "\n",
    "Following the model creation, fine-tuning is performed on the augmented dataset. During fine-tuning, various hyperparameter configurations and feature selections are experimented with.\n",
    "\n",
    "The training process is conducted in two stages: initially, a binary classification determines whether a data point exhibits sexism, followed by a more detailed classification of the level of sexism for each predicted instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q\n",
    "!pip install torch -q\n",
    "!pip install textblob -q\n",
    "!pip install spacy -q\n",
    "!pip install transformers[torch] -q\n",
    "!pip install accelerate -U -q\n",
    "!python -m spacy download de_core_news_sm -q\n",
    "!pip install germansentiment -q\n",
    "!pip install matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5UtEvkqwlhWa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, AutoModel, pipeline, get_linear_schedule_with_warmup\n",
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from textblob import TextBlob\n",
    "from spacy.lang.de.examples import sentences\n",
    "from tqdm import tqdm\n",
    "from germansentiment import SentimentModel\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3Abea0_0iMZ"
   },
   "source": [
    "### Model Building\n",
    "\n",
    "Various pre-trained models were evaluated, all specifically trained on the German language or multilingual datasets. Eventually, fine-tuning and feature engineering with bert-base-german-cased yielded the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ECrO6ePK5Mys"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "ANNOTATOR_COLUMNS = ['A001', 'A002', 'A003', 'A004', 'A005', 'A007', 'A008', 'A009', 'A010', 'A012']\n",
    "\n",
    "checkpoint = \"google-bert/bert-base-german-cased\"\n",
    "\n",
    "# \"google-bert/bert-base-german-cased\"\n",
    "# \"google-bert/bert-base-multilingual-cased\"\n",
    "# \"FacebookAI/xlm-roberta-large-finetuned-conll03-german\"\n",
    "# \"ml6team/distilbert-base-german-cased-toxic-comments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NxOFR4dN5EbC"
   },
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-task Transformer model using BERT-based embeddings for annotation tasks.\n",
    "    Each tasks corresponds to the prediction of one annotator.\n",
    "\n",
    "    Args:\n",
    "        tfidf_dicts (dict): Dictionary containing TF-IDF scores for each document.\n",
    "        nr_preds (int): Number of predictions per annotator (either 2 for binary, 4 for multi-class).\n",
    "        num_annotators (int): Number of annotators.\n",
    "        bert_model (str): Pre-trained BERT model checkpoint.\n",
    "        bert_dim (int): Dimension of BERT embeddings. Typically 768, however larger when incorporating additional features.\n",
    "        tfidf (bool): Flag indicating whether to use TF-IDF features.\n",
    "        sent (bool): Flag indicating whether to include sentiment feature\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tfidf_dicts=None, nr_preds=2, num_annotators=10, bert_model=checkpoint, bert_dim=768, tfidf=False, sent=False):\n",
    "        \n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.num_annotators = num_annotators\n",
    "        self.tfidf_dicts = tfidf_dicts\n",
    "        self.nr_preds = nr_preds\n",
    "        self.tfidf = tfidf\n",
    "        self.sent = sent\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint)\n",
    "        self.sentiment_model = SentimentModel()\n",
    "        \n",
    "        self.bert_dim = bert_dim\n",
    "        if sent:\n",
    "            self.bert_dim = bert_dim + 3\n",
    "\n",
    "        # Shared layers\n",
    "        self.shared_dense1 = nn.Linear(self.bert_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.shared_dense2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        # Annotator-specific output layers\n",
    "        self.annotator_heads = nn.ModuleDict({\n",
    "            str(name): nn.Linear(64, nr_preds) for name in ANNOTATOR_COLUMNS\n",
    "        })\n",
    "\n",
    "    def forward(self, input_ids, doc_idx, attention_mask=None, token_type_ids=None):\n",
    "        \"\"\"\n",
    "        Performs forward pass through the model.\n",
    "        \"\"\"\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, return_dict=True) #token_type_ids=token_type_ids,\n",
    "\n",
    "        # Extract the CLS token output for classification\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :] # shape 8x768\n",
    "\n",
    "        # Apply TF-IDF features if enabled\n",
    "        if self.tfidf:\n",
    "            tfidf_scores = self.compute_tfidf(input_ids, doc_idx)\n",
    "            cls_token = cls_token * tfidf_scores[:, 0].unsqueeze(-1)\n",
    "\n",
    "        # Apply sentiment analysis features if enabled\n",
    "        if self.sent:\n",
    "            additional_features = self.compute_additional_features(input_ids)\n",
    "            # Concatenate CLS token with additional features\n",
    "            cls_token = torch.cat((cls_token, additional_features), dim=1)\n",
    "\n",
    "        # Shared layers\n",
    "        shared_layer = self.shared_dense1(cls_token) # weigths shape 512x128\n",
    "        shared_layer = torch.relu(shared_layer)\n",
    "        shared_layer = self.dropout1(shared_layer)\n",
    "        shared_layer = self.batch_norm1(shared_layer)\n",
    "\n",
    "        shared_layer = self.shared_dense2(shared_layer)\n",
    "        shared_layer = torch.relu(shared_layer)\n",
    "        shared_layer = self.dropout2(shared_layer)\n",
    "        shared_layer = self.batch_norm2(shared_layer)\n",
    "\n",
    "        # Annotator-specific heads for binary and multi-label classification\n",
    "        if self.nr_preds==2:\n",
    "            outputs = {str(column_name): torch.sigmoid(head(shared_layer)) for column_name, head in self.annotator_heads.items()}\n",
    "        elif self.nr_preds==4:\n",
    "            outputs = {str(column_name): torch.softmax(head(shared_layer), dim=-1) for column_name, head in self.annotator_heads.items()}\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_tfidf(self, input_ids, doc_idx):\n",
    "        \"\"\"\n",
    "        Computes TF-IDF scores for input tokens.\n",
    "        \"\"\"\n",
    "        batch_size = input_ids.size(0)\n",
    "        tfidf_scores_batch = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            tfidf_dict = self.tfidf_dicts[doc_idx[i].item()]\n",
    "            tfidf_scores = torch.tensor(\n",
    "              [tfidf_dict.get(self.tokenizer.decode([input_id]), 1.0) for input_id in input_ids[i]]\n",
    "            ).float()\n",
    "            tfidf_scores = tfidf_scores.to(input_ids.device) \n",
    "            tfidf_scores_batch.append(tfidf_scores)\n",
    "\n",
    "        tfidf_scores_batch = torch.stack(tfidf_scores_batch)\n",
    "        return tfidf_scores_batch\n",
    "\n",
    "    def compute_additional_features(self, input_ids):\n",
    "        \"\"\"\n",
    "        Computes additional features for input tokens. It was experimented with sentiment, length\n",
    "        of entry, question and exclamation mark ratio.\n",
    "        \"\"\"\n",
    "            \n",
    "        additional_features = []\n",
    "\n",
    "        for input_id in input_ids:\n",
    "            text = self.tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "            #text_length = len(text.split())\n",
    "            #question_mark_ratio = text.count('?') / text_length if text_length > 0 else 0\n",
    "            #exclamation_mark_ratio = text.count('!') / text_length if text_length > 0 else 0\n",
    "\n",
    "            classes, probabilities = self.sentiment_model.predict_sentiment([text], output_probabilities = True)\n",
    "            sentiment_positive = probabilities[0][0][1]\n",
    "            sentiment_negative = probabilities[0][1][1]\n",
    "            sentiment_neutral = probabilities[0][2][1]\n",
    "            additional_features.append([sentiment_positive, sentiment_negative, sentiment_neutral])\n",
    "\n",
    "        return torch.tensor(additional_features).to(input_ids.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detailed explanation about the incorporation of tf-idf scores can be found in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI-kxZ2s0l88"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "For fine-tuning we experimented a lot with the combination of additional features as well as pre-processing, such as upsampling minority classes or applying lemmatization to the dataframe. Both techniques yielded worse performance, thus were not utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_minority_classes(df):\n",
    "    \"\"\"\n",
    "    Upsamples minority classes in a DataFrame for each annotator column. Only for binary df.\n",
    "    \"\"\"\n",
    "    upsampled_dfs = []\n",
    "\n",
    "    for annotator in ANNOTATOR_COLUMNS:\n",
    "        majority_class = df[df[annotator] == 0]\n",
    "        minority_class = df[df[annotator] == 1]\n",
    "        \n",
    "        minority_upsampled = resample(\n",
    "            minority_class, \n",
    "            replace=True,  \n",
    "            n_samples=majority_class.shape[0], \n",
    "            random_state=42 \n",
    "        )\n",
    "        \n",
    "        upsampled_df = pd.concat([majority_class, minority_upsampled])\n",
    "        upsampled_dfs.append(upsampled_df)\n",
    "    \n",
    "    combined_upsampled_df = pd.concat(upsampled_dfs).drop_duplicates().reset_index(drop=True)  \n",
    "    return combined_upsampled_df\n",
    "\n",
    "def lemma(text):\n",
    "    \"\"\" \n",
    "    Apply lemmatization and stopword removal. \n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    result = ' '.join([\n",
    "        token.text if token.is_punct else token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "    ])\n",
    "    return result.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_df(split, path, upsample=False, lemmat=False):\n",
    "    \"\"\"\n",
    "    Prepares training dataframes for binary and multi-class classification tasks with optional \n",
    "    data preprocessing, specifically upsampling and lemmatization. Method offers possibility\n",
    "    to get only the original df, the df augmented once or augmented twice.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    #df = df.drop('A011', axis=1)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    if split == 1:\n",
    "        end_index = 4486\n",
    "    elif split == 2:\n",
    "        end_index = 8972\n",
    "    elif split==3:\n",
    "        end_index = len(df)\n",
    "    \n",
    "    df = df[:end_index]\n",
    "\n",
    "    # Binary classification\n",
    "    df_bin = df.copy()\n",
    "    df_bin[ANNOTATOR_COLUMNS] = df_bin[ANNOTATOR_COLUMNS].replace([2, 3, 4], 1)\n",
    "\n",
    "    # Multi-class classification\n",
    "    replace_dict = {0: -1, 1: 0, 2: 1, 3: 2, 4: 3}\n",
    "    df_mul = df.copy()\n",
    "    df_mul[ANNOTATOR_COLUMNS] = df_mul[ANNOTATOR_COLUMNS].replace(replace_dict)\n",
    "\n",
    "    if upsample:\n",
    "        df_bin = upsample_minority_classes(df_bin)\n",
    "        df_mul = upsample_minority_classes(df_mul)\n",
    "    if lemmat:\n",
    "        df_bin['text'] = df_bin['text'].apply(lambda x: lemma(x))\n",
    "        df_mul['text'] = df_mul['text'].apply(lambda x: lemma(x))\n",
    "    \n",
    "    return df, df_bin, df_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QzCG9Xhw00-5"
   },
   "outputs": [],
   "source": [
    "class MultiTaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a PyTorch Dataset for multi-task learning with BERT-based models.\n",
    "\n",
    "    Args:\n",
    "        dataframe (DataFrame): Pandas DataFrame containing text data and annotations.\n",
    "        max_len (int): Maximum length of tokenized inputs for padding/truncation.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, max_len):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.dataframe.iloc[item]['text']\n",
    "        labels = {annotator: torch.tensor(int(self.dataframe.iloc[item][annotator]), dtype=torch.int)\n",
    "                  for annotator in ANNOTATOR_COLUMNS}\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': labels,\n",
    "            'doc_idx': torch.tensor(item, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4-jSMcaPYrQd"
   },
   "outputs": [],
   "source": [
    "def get_tfidf_dict(df):\n",
    "    \"\"\"\n",
    "    Utilizes TfidfVectorizer to compute TF-IDF scores for words in the text data stored in a DataFrame.\n",
    "    Returns a list of dictionaries, where each dictionary maps words to their corresponding TF-IDF scores \n",
    "    for each document in the DataFrame. \n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(df['text'])\n",
    "    tfidf_scores = X.toarray()\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    tfidf_dicts = [] \n",
    "    for doc_idx, doc in enumerate(df['text']):\n",
    "        tfidf_dict = {word: tfidf_scores[doc_idx, idx] for idx, word in enumerate(feature_names) if tfidf_scores[doc_idx, idx] > 0}\n",
    "        tfidf_dicts.append(tfidf_dict)\n",
    "    return tfidf_dicts\n",
    "\n",
    "def compute_class_weights(df, annotator_column):\n",
    "    \"\"\" \n",
    "    To address the highly imbalanced dataframes, class weights for every annotator are calculated.\n",
    "    \"\"\"\n",
    "    y = df[annotator_column].values\n",
    "    y_filtered = y[y != -1]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_filtered), y=y_filtered)\n",
    "    return torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEx8mZoYLhtp"
   },
   "source": [
    "### Define Data & Training Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>A012</th>\n",
       "      <th>A003</th>\n",
       "      <th>A005</th>\n",
       "      <th>A001</th>\n",
       "      <th>A008</th>\n",
       "      <th>A004</th>\n",
       "      <th>A007</th>\n",
       "      <th>A010</th>\n",
       "      <th>A002</th>\n",
       "      <th>A009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wen man nicht reinläßt, den muss man auch nich...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und eine Katze die schnurrt genügt Ihnen? \\nUn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  A012  A003  A005  A001  \\\n",
       "0  Wen man nicht reinläßt, den muss man auch nich...    -1    -1    -1    -1   \n",
       "1  Und eine Katze die schnurrt genügt Ihnen? \\nUn...     0     0    -1    -1   \n",
       "\n",
       "   A008  A004  A007  A010  A002  A009  \n",
       "0    -1    -1    -1    -1    -1    -1  \n",
       "1     0    -1     0    -1    -1    -1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='df_train_original.csv'\n",
    "# order: df normal, df binary, df multi-class\n",
    "_, _, df = get_train_df(split=3, path=path, upsample=False, lemmat=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion_dict():\n",
    "    \"\"\" \n",
    "    Creates a dictionary of loss functions (criterions) for each annotator with class weights to handle imbalanced data.\n",
    "    \"\"\"\n",
    "    class_weights_dict = {}\n",
    "    criterion_dict = {}\n",
    "\n",
    "    for annotator in ANNOTATOR_COLUMNS:\n",
    "        class_weights = compute_class_weights(df, annotator)\n",
    "        class_weights_dict[annotator] = class_weights.to(device)\n",
    "        criterion_dict[annotator] = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    return criterion_dict\n",
    "\n",
    "criterion_dict = get_criterion_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1tnyucG6agat"
   },
   "outputs": [],
   "source": [
    "max_len = 64 # as median and avg are 32\n",
    "batch_size = 16\n",
    "num_epochs = 8 # 7 for binary prediction, 8 epochs for multi-class \n",
    "learning_rate = 0.01 # 0.005 for binary prediction, 0.01 for multi-class \n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "yvVyGOtHX4Ot"
   },
   "outputs": [],
   "source": [
    "tfidf_dicts = get_tfidf_dict(df)\n",
    "model = MultiTaskModel(nr_preds=4, tfidf_dicts=tfidf_dicts, tfidf=True, sent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_mapping = {str(i): annotator for i, annotator in enumerate(df.columns[1:], start=0)}\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#scheduler = get_linear_schedule_with_warmup(optimizer=sgd, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "#scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df, val_df = train_test_split(shuffled_df, test_size=0.15, random_state=42)\n",
    "\n",
    "train_dataset = MultiTaskDataset(train_df, max_len)\n",
    "val_dataset = MultiTaskDataset(val_df, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset = MultiTaskDataset(df, max_len)\n",
    "#train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(train_loader) * num_epochs\n",
    "warmup_steps = 0.1 * total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation while training after each epoch to control num epochs\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided data loader. Will be called after each fine-tune epoch to supervise training.\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    \n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    test_batches = 0\n",
    "    test_precision = 0\n",
    "    test_recall = 0\n",
    "    test_f1 = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch_idx, batch in enumerate(tqdm(loader, desc=f'Evaluating...')):\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            doc_idx = batch['doc_idx'].to(device)\n",
    "            #model.to(device)\n",
    "\n",
    "            outputs = model(input_ids, doc_idx, attention_mask)\n",
    "            loss = 0\n",
    "\n",
    "            for annotator, logits in outputs.items():\n",
    "                annotator_labels = labels[annotator].long().to(device)\n",
    "                mask = annotator_labels != -1  \n",
    "                if mask.sum() > 0: \n",
    "                    masked_logits = logits[mask]\n",
    "                    masked_labels = annotator_labels[mask]\n",
    "\n",
    "                    criterion = criterion_dict[annotator]\n",
    "                    loss += criterion(masked_logits, masked_labels)\n",
    "\n",
    "                    predicted_labels = torch.argmax(masked_logits, dim=1).cpu().numpy()\n",
    "                    true_labels = masked_labels.cpu().numpy()\n",
    "\n",
    "                    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "                    precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "                    recall = recall_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "                    f1 = f1_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "\n",
    "                    test_accuracy += accuracy\n",
    "                    test_precision += precision\n",
    "                    test_recall += recall\n",
    "                    test_f1 += f1\n",
    "\n",
    "                    test_batches += 1\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    avg_loss = test_loss / len(loader)\n",
    "    avg_accuracy = test_accuracy / test_batches\n",
    "    avg_precision = test_precision / test_batches\n",
    "    avg_recall = test_recall / test_batches\n",
    "    avg_f1 = test_f1 / test_batches\n",
    "\n",
    "    print(f'Loss: {avg_loss:.3f}, Accuracy: {avg_accuracy:.3f}, Precision: {avg_precision:.3f}, Recall: {avg_recall:.3f}, F1 Score: {avg_f1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qu2sxFR3rdG1",
    "outputId": "67b71798-121f-425c-e59b-80b06e3b4188"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    This function trains the given model using the training data loader for a specified number of epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, num_epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        total_batches = 0\n",
    "        total_precision = 0\n",
    "        total_recall = 0\n",
    "        total_f1 = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}')):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            doc_idx = batch['doc_idx'].to(device)\n",
    "\n",
    "            model.to(device)\n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad() # clear any previously calculated gradients\n",
    "            outputs = model(input_ids, doc_idx, attention_mask)\n",
    "\n",
    "            loss = 0\n",
    "            for annotator, logits in outputs.items():\n",
    "                annotator_labels = labels[annotator].long()\n",
    "                mask = annotator_labels != -1  # -1 indicates not present labels\n",
    "                if mask.sum() > 0:\n",
    "                    masked_logits = logits[mask]\n",
    "                    masked_labels = annotator_labels[mask].to(logits.device)\n",
    "\n",
    "                    criterion = criterion_dict[annotator]\n",
    "                    loss += criterion(masked_logits, masked_labels)\n",
    "\n",
    "                    predicted_labels = torch.argmax(masked_logits, dim=1)\n",
    "                    accuracy = accuracy_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "                    precision = precision_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "                    recall = recall_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "                    f1 = f1_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "\n",
    "                    total_accuracy += accuracy\n",
    "                    total_precision += precision\n",
    "                    total_recall += recall\n",
    "                    total_f1 += f1\n",
    "\n",
    "                    total_batches += 1\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient Clipping\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_accuracy = total_accuracy / total_batches\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_precision = total_precision / total_batches\n",
    "        avg_recall = total_recall / total_batches\n",
    "        avg_f1 = total_f1 / total_batches\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss, Accuracy, Precision, Recall, F1: {avg_loss:.3f}, {avg_accuracy:.3f}, {avg_precision:.3f}, {avg_recall:.3f}, {avg_f1:.3f}')\n",
    "\n",
    "        # evaluation after each epoch\n",
    "        evaluate(model, val_loader)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 952/952 [02:01<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Loss, Accuracy, Precision, Recall, F1: 11.489, 0.276, 0.494, 0.541, 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.608, Accuracy: 0.346, Precision: 0.682, Recall: 0.527, F1 Score: 0.277\n",
      "\n",
      "======== Epoch 2 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8: 100%|██████████| 952/952 [02:02<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8, Loss, Accuracy, Precision, Recall, F1: 11.437, 0.331, 0.524, 0.544, 0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.405, Accuracy: 0.421, Precision: 0.697, Recall: 0.539, F1 Score: 0.331\n",
      "\n",
      "======== Epoch 3 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8: 100%|██████████| 952/952 [02:02<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8, Loss, Accuracy, Precision, Recall, F1: 11.306, 0.378, 0.573, 0.543, 0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.354, Accuracy: 0.452, Precision: 0.764, Recall: 0.542, F1 Score: 0.340\n",
      "\n",
      "======== Epoch 4 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8: 100%|██████████| 952/952 [02:02<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8, Loss, Accuracy, Precision, Recall, F1: 11.156, 0.412, 0.623, 0.543, 0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.030, Accuracy: 0.464, Precision: 0.771, Recall: 0.541, F1 Score: 0.347\n",
      "\n",
      "======== Epoch 5 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8: 100%|██████████| 952/952 [02:03<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8, Loss, Accuracy, Precision, Recall, F1: 11.127, 0.427, 0.647, 0.544, 0.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.127, Accuracy: 0.474, Precision: 0.773, Recall: 0.551, F1 Score: 0.358\n",
      "\n",
      "======== Epoch 6 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8: 100%|██████████| 952/952 [02:02<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/8, Loss, Accuracy, Precision, Recall, F1: 11.183, 0.423, 0.652, 0.544, 0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.089, Accuracy: 0.438, Precision: 0.760, Recall: 0.543, F1 Score: 0.336\n",
      "\n",
      "======== Epoch 7 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8: 100%|██████████| 952/952 [02:02<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Loss, Accuracy, Precision, Recall, F1: 11.159, 0.417, 0.645, 0.541, 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.162, Accuracy: 0.474, Precision: 0.771, Recall: 0.557, F1 Score: 0.362\n",
      "\n",
      "======== Epoch 8 / 8 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8: 100%|██████████| 952/952 [02:03<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8, Loss, Accuracy, Precision, Recall, F1: 11.162, 0.427, 0.658, 0.546, 0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 168/168 [00:12<00:00, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.025, Accuracy: 0.445, Precision: 0.762, Recall: 0.540, F1 Score: 0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, train_loader, val_loader, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method used to predict values in test df\n",
    "\n",
    "def predict(model, df, binary_prediction):\n",
    "    \"\"\"\n",
    "    Predicts the values for the given datafrane using the provided model.\n",
    "    \"\"\"\n",
    "        \n",
    "    global batch_size\n",
    "    dataset = MultiTaskDataset(df, max_len)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    start_idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(loader, desc=\"Predicting\")):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            doc_idx = batch['doc_idx'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, doc_idx, attention_mask)\n",
    "            \n",
    "            batch_size = input_ids.size(0)\n",
    "            end_idx = start_idx + batch_size\n",
    "            \n",
    "            for annotator in ANNOTATOR_COLUMNS:\n",
    "                logits = outputs[annotator]\n",
    "                predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                \n",
    "                for i in range(start_idx, end_idx):\n",
    "                    if binary_prediction:\n",
    "                        if df.at[i, annotator] == 1:\n",
    "                            df.at[i, annotator] = predicted_labels[i - start_idx]\n",
    "                    else: \n",
    "                        if df.at[i, annotator] == 1:\n",
    "                            df.at[i, annotator] = predicted_labels[i - start_idx] + 1\n",
    "                        else: \n",
    "                            df.at[i, annotator] = -1\n",
    "            \n",
    "            start_idx = end_idx\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition = pd.read_csv('df_comp_bin_2.csv')\n",
    "df_preds = predict(model, df_competition)\n",
    "df_preds = df_preds.drop('Unnamed: 0', axis=1)\n",
    "df_preds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preds.to_csv('df_comp_multi_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Evaluation is performed using cross validation and computing a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "\n",
      "Epoch 1/8, Loss: 11.308426195489508, Accuracy: 0.25386508290763504, Precision: 0.4838665827804495, Recall: 0.5392408433288692\n",
      "\n",
      "Epoch 2/8, Loss: 11.328097369521856, Accuracy: 0.25346645707215987, Precision: 0.4845768809763203, Recall: 0.540022403715167\n",
      "\n",
      "Epoch 3/8, Loss: 11.370048411988787, Accuracy: 0.2507820152756596, Precision: 0.4804107254035532, Recall: 0.538109826865467\n",
      "\n",
      "Epoch 4/8, Loss: 11.34901222373758, Accuracy: 0.2569289559022612, Precision: 0.4842321795247902, Recall: 0.539920933694038\n",
      "\n",
      "Epoch 5/8, Loss: 11.314176713249513, Accuracy: 0.2626059715837577, Precision: 0.4874571506924483, Recall: 0.5444264477352729\n",
      "\n",
      "Epoch 6/8, Loss: 11.338849129953555, Accuracy: 0.25441612717236073, Precision: 0.4832115343625369, Recall: 0.5372513316325004\n",
      "\n",
      "Epoch 7/8, Loss: 11.32254196703434, Accuracy: 0.2557446958462181, Precision: 0.4837790201368919, Recall: 0.5404281593050649\n",
      "\n",
      "Epoch 8/8, Loss: 11.365990069827863, Accuracy: 0.2554909681908449, Precision: 0.48468824503059976, Recall: 0.5403590328892739\n",
      "Fold 1/5, Loss: 9.14139672262328, Accuracy: 0.24954151939545918, Precision: 0.4440228848559347, Recall: 0.49725713315217346\n",
      "Fold 2/5\n",
      "\n",
      "Epoch 1/8, Loss: 11.77635531393545, Accuracy: 0.25570652199754573, Precision: 0.48101082992838917, Recall: 0.5347038899035778\n",
      "\n",
      "Epoch 2/8, Loss: 11.812418457652841, Accuracy: 0.2509383296296037, Precision: 0.4809193774452384, Recall: 0.534478325260009\n",
      "\n",
      "Epoch 3/8, Loss: 11.817327013505357, Accuracy: 0.25681474158749784, Precision: 0.4838073032969937, Recall: 0.5376813679191217\n",
      "\n",
      "Epoch 4/8, Loss: 11.806347594197307, Accuracy: 0.25726398212584145, Precision: 0.48206065722346814, Recall: 0.5369708037580718\n",
      "\n",
      "Epoch 5/8, Loss: 11.877896932086774, Accuracy: 0.2503716447891837, Precision: 0.4795558827806888, Recall: 0.5346544658439307\n",
      "\n",
      "Epoch 6/8, Loss: 11.770206693559885, Accuracy: 0.25721944399695673, Precision: 0.4844973387877206, Recall: 0.5380147131211083\n",
      "\n",
      "Epoch 7/8, Loss: 11.800768625523363, Accuracy: 0.2595432520695669, Precision: 0.48363873224728804, Recall: 0.5390653456558088\n",
      "\n",
      "Epoch 8/8, Loss: 11.846377566722888, Accuracy: 0.25460816146030374, Precision: 0.48273291970696863, Recall: 0.5352879025731003\n",
      "Fold 2/5, Loss: 7.6108265455280035, Accuracy: 0.2568898031031576, Precision: 0.45477838529548603, Recall: 0.5022340817434462\n",
      "Fold 3/5\n",
      "\n",
      "Epoch 1/8, Loss: 11.555309988026108, Accuracy: 0.2603027706170322, Precision: 0.4854157340257284, Recall: 0.5370543308647691\n",
      "\n",
      "Epoch 2/8, Loss: 11.530800199934415, Accuracy: 0.2548218348029739, Precision: 0.483311923044851, Recall: 0.5355807453881026\n",
      "\n",
      "Epoch 3/8, Loss: 11.58720528068287, Accuracy: 0.2564812913499761, Precision: 0.48431223666383916, Recall: 0.5383445899240513\n",
      "\n",
      "Epoch 4/8, Loss: 11.496218680803265, Accuracy: 0.2503156846007222, Precision: 0.4789130663302873, Recall: 0.5336451113084798\n",
      "\n",
      "Epoch 5/8, Loss: 11.541694320206132, Accuracy: 0.256960974189841, Precision: 0.48491690185011177, Recall: 0.538257786651821\n",
      "\n",
      "Epoch 6/8, Loss: 11.563000976507153, Accuracy: 0.2543125369764266, Precision: 0.4807984805063011, Recall: 0.5355707137099882\n",
      "\n",
      "Epoch 7/8, Loss: 11.59020923929555, Accuracy: 0.2528991429574451, Precision: 0.4826263235491239, Recall: 0.5383928571428596\n",
      "\n",
      "Epoch 8/8, Loss: 11.567251042063747, Accuracy: 0.2570917343571385, Precision: 0.4836874077057344, Recall: 0.5371562471366166\n",
      "Fold 3/5, Loss: 8.047291758869376, Accuracy: 0.24423598786079492, Precision: 0.4573907711089916, Recall: 0.4920464481375501\n",
      "Fold 4/5\n",
      "\n",
      "Epoch 1/8, Loss: 11.636089814560753, Accuracy: 0.2575446155487514, Precision: 0.48287843786476153, Recall: 0.5375108434538932\n",
      "\n",
      "Epoch 2/8, Loss: 11.65992847563965, Accuracy: 0.25676580382560593, Precision: 0.4860520999822442, Recall: 0.5381042892871959\n",
      "\n",
      "Epoch 3/8, Loss: 11.648171026791845, Accuracy: 0.2526894683748926, Precision: 0.48113470684980425, Recall: 0.5348430716688166\n",
      "\n",
      "Epoch 4/8, Loss: 11.680953303618091, Accuracy: 0.2520646474596461, Precision: 0.48192153950732397, Recall: 0.5338202875466822\n",
      "\n",
      "Epoch 5/8, Loss: 11.631413526833057, Accuracy: 0.2520966135449303, Precision: 0.48233915004748673, Recall: 0.5357744481116894\n",
      "\n",
      "Epoch 6/8, Loss: 11.659125416938748, Accuracy: 0.2560267264849032, Precision: 0.4828569895814858, Recall: 0.5385556728907172\n",
      "\n",
      "Epoch 7/8, Loss: 11.693258320114442, Accuracy: 0.2514227206195045, Precision: 0.4808470846040644, Recall: 0.5371644173215424\n",
      "\n",
      "Epoch 8/8, Loss: 11.695932117956024, Accuracy: 0.2573960673947391, Precision: 0.4873229540123073, Recall: 0.5384815513865471\n",
      "Fold 4/5, Loss: 8.506743058562279, Accuracy: 0.24637431820145145, Precision: 0.45860801407847435, Recall: 0.5013474262790459\n",
      "Fold 5/5\n",
      "\n",
      "Epoch 1/8, Loss: 11.762275003961154, Accuracy: 0.2609115184326204, Precision: 0.48552767519564205, Recall: 0.5370316680483883\n",
      "\n",
      "Epoch 2/8, Loss: 11.765974558889866, Accuracy: 0.2630385772781655, Precision: 0.4845222667787928, Recall: 0.5384964825413581\n",
      "\n",
      "Epoch 3/8, Loss: 11.752990100000586, Accuracy: 0.2566218133375894, Precision: 0.4824931467918416, Recall: 0.5377094720390531\n",
      "\n",
      "Epoch 4/8, Loss: 11.729015971933093, Accuracy: 0.25650800911658905, Precision: 0.4833437111161582, Recall: 0.5361249700489331\n",
      "\n",
      "Epoch 5/8, Loss: 11.752027598608818, Accuracy: 0.25320713665281397, Precision: 0.4816606193539209, Recall: 0.5371825029685875\n",
      "\n",
      "Epoch 6/8, Loss: 11.72045646873968, Accuracy: 0.255136504762134, Precision: 0.4824291961682662, Recall: 0.5372633430304745\n",
      "\n",
      "Epoch 7/8, Loss: 11.845470932445355, Accuracy: 0.2516841245789295, Precision: 0.4820121087959523, Recall: 0.5318730585536099\n",
      "\n",
      "Epoch 8/8, Loss: 11.783829613987889, Accuracy: 0.25725754018662006, Precision: 0.48438589360518247, Recall: 0.5371116662970098\n",
      "Fold 5/5, Loss: 6.7168897699032515, Accuracy: 0.2395702098292291, Precision: 0.4151226818201842, Recall: 0.4760043610413636\n",
      "Average Loss: 101.01531802240231\n",
      "Average Accuracy: 2.291187209489496\n",
      "Average Precision: 4.311215550282926\n",
      "Average Recall: 4.79211107417503\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "cv_losses = []\n",
    "cv_accuracies = []\n",
    "cv_precisions = []\n",
    "cv_recalls = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f'Fold {fold + 1}/{kf.n_splits}')\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()  \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        total_batches = 0\n",
    "        total_precision = 0\n",
    "        total_recall = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            doc_idx = batch['doc_idx'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, doc_idx, attention_mask)\n",
    "\n",
    "            loss = 0\n",
    "            for annotator, logits in outputs.items():\n",
    "                annotator_labels = labels[annotator].long().to(device)\n",
    "                mask = annotator_labels != -1\n",
    "                if mask.sum() > 0:\n",
    "                    masked_logits = logits[mask]\n",
    "                    masked_labels = annotator_labels[mask]\n",
    "\n",
    "                    criterion = criterion_dict[annotator]\n",
    "                    loss += criterion(masked_logits, masked_labels)\n",
    "\n",
    "                    predicted_labels = torch.argmax(masked_logits, dim=1)\n",
    "                    accuracy = accuracy_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "                    total_accuracy += accuracy\n",
    "\n",
    "                    precision = precision_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "                    recall = recall_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "                    total_precision += precision\n",
    "                    total_recall += recall\n",
    "\n",
    "                    total_batches += 1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_accuracy = total_accuracy / total_batches\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_precision = total_precision / total_batches\n",
    "        avg_recall = total_recall / total_batches\n",
    "\n",
    "        cv_losses.append(avg_loss)\n",
    "        cv_accuracies.append(avg_accuracy)\n",
    "        cv_precisions.append(avg_precision)\n",
    "        cv_recalls.append(avg_recall)\n",
    "\n",
    "        print(\"\")\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}, Accuracy: {avg_accuracy}, Precision: {avg_precision}, Recall: {avg_recall}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    val_batches = 0\n",
    "    val_precision = 0\n",
    "    val_recall = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "            doc_idx = batch['doc_idx'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, doc_idx, attention_mask)\n",
    "            batch_loss = 0\n",
    "\n",
    "            for annotator, logits in outputs.items():\n",
    "                annotator_labels = labels[annotator].long().to(device)\n",
    "                mask = annotator_labels != -1 \n",
    "                if mask.sum() > 0: \n",
    "                    masked_logits = logits[mask]\n",
    "                    masked_labels = annotator_labels[mask]\n",
    "                    \n",
    "                    criterion = criterion_dict[annotator]\n",
    "                    batch_loss += criterion(masked_logits, masked_labels)\n",
    "\n",
    "                    predicted_labels = torch.argmax(masked_logits, dim=1)\n",
    "                    accuracy = accuracy_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "                    val_accuracy += accuracy\n",
    "                    precision = precision_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "                    recall = recall_score(masked_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average='macro', zero_division=1)\n",
    "                    val_precision += precision\n",
    "                    val_recall += recall\n",
    "\n",
    "                    val_batches += 1\n",
    "\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "    avg_val_accuracy = val_accuracy / val_batches\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_precision = val_precision / val_batches\n",
    "    avg_val_recall = val_recall / val_batches\n",
    "\n",
    "    cv_losses.append(avg_val_loss)\n",
    "    cv_accuracies.append(avg_val_accuracy)\n",
    "    cv_precisions.append(avg_val_precision)\n",
    "    cv_recalls.append(avg_val_recall)\n",
    "\n",
    "    print(f'Fold {fold + 1}/{kf.n_splits}, Loss: {avg_val_loss}, Accuracy: {avg_val_accuracy}, Precision: {avg_val_precision}, Recall: {avg_val_recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix on test data\n",
    "model.eval() \n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        doc_idx = batch['doc_idx'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, doc_idx, attention_mask)\n",
    "\n",
    "        for annotator, logits in outputs.items():\n",
    "            annotator_labels = labels[annotator].long().to(device)\n",
    "            mask = annotator_labels != -1 \n",
    "            if mask.sum() > 0: \n",
    "                masked_logits = logits[mask]\n",
    "                masked_labels = annotator_labels[mask]\n",
    "                \n",
    "                predicted_labels = torch.argmax(masked_logits, dim=1)\n",
    "                \n",
    "                all_true_labels.extend(masked_labels.cpu().numpy())\n",
    "                all_pred_labels.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary\n",
    "train_losses = [6.327, 5.682, 5.286, 5.034, 4.817, 4.676, 4.528]\n",
    "train_accuracies = [0.635, 0.726, 0.770, 0.802, 0.824, 0.839, 0.855]\n",
    "\n",
    "# multi-class\n",
    "train_losses = [11.489, 11.437, 11.306, 11.156, 11.127, 11.183, 11.159,  11.162]\n",
    "train_accuracies = [0.276, 0.331, 0.378, 0.412, 0.427, 0.423, 0.417, 0.427]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "W5KAjAsdlhWn",
    "outputId": "fe26096e-62d3-4e8c-9964-1d42bf4e2776"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_plots.png', dpi=300)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Other code experimented with but not used in final implementation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(weight=self.alpha, reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
